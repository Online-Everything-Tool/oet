# .github/workflows/validate-generated-tool-pr.yml
name: Validate Generated Tool PR

on:
  pull_request:
    types: [opened, synchronize]
    branches:
      - main
  issue_comment:
    types: [created]

jobs:
  trigger_gatekeeper:
    name: 0.A Check Comment Trigger (for issue_comment event)
    # Only run for issue_comment events that are on a pull request
    if: github.event_name == 'issue_comment' && github.event.issue.pull_request != null
    runs-on: ubuntu-latest
    outputs:
      should_run_validation: ${{ steps.check_comment.outputs.should_run_validation }}
      pr_number: ${{ steps.check_comment.outputs.pr_number }}
      pr_head_sha: ${{ steps.check_comment.outputs.pr_head_sha }}
      pr_head_ref: ${{ steps.check_comment.outputs.pr_head_ref }}
    permissions:
      pull-requests: read # Needed for GITHUB_TOKEN to fetch PR details
    steps:
      - name: Check comment for command
        id: check_comment
        env:
          COMMENT_BODY: ${{ github.event.comment.body }}
          COMMENTER_LOGIN: ${{ github.event.comment.user.login }}
          # IMPORTANT: This should be the login of the actor that posts the /revalidate-ai-fixes comment.
          # If AI Lint Fixer uses GITHUB_TOKEN to comment, this is 'github-actions[bot]'
          AUTHORIZED_ACTOR: "github-actions[bot]" # Adjust if your AI Lint Fixer comments as a different actor
        run: |
          echo "Comment body: \"$COMMENT_BODY\""
          echo "Commenter: \"$COMMENTER_LOGIN\""
          echo "Expected authorized actor: \"$AUTHORIZED_ACTOR\""
          
          IS_AUTHORIZED="false"
          if [[ "$COMMENTER_LOGIN" == "$AUTHORIZED_ACTOR" ]]; then
            IS_AUTHORIZED="true"
          fi
          echo "Is authorized: $IS_AUTHORIZED"

          SHOULD_RUN="false" # Default to not running validation
          TRIMMED_COMMENT_BODY=$(echo "$COMMENT_BODY" | xargs) # Trim whitespace

          if [[ "$TRIMMED_COMMENT_BODY" == "/revalidate-ai-fixes" && "$IS_AUTHORIZED" == "true" ]]; then
            echo "::notice::Re-validation command recognized from authorized actor."
            
            PR_URL="${{ github.event.issue.pull_request.url }}" # API URL for the PR
            echo "Fetching PR details from: $PR_URL"
            
            PR_DETAILS_RESPONSE=$(curl -s -w "\n%{http_code}" -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
                                   -H "Accept: application/vnd.github.v3+json" \
                                   "$PR_URL")
            
            PR_HTTP_CODE=$(echo "$PR_DETAILS_RESPONSE" | tail -n1)
            PR_DETAILS=$(echo "$PR_DETAILS_RESPONSE" | sed '$d')

            if [[ "$PR_HTTP_CODE" -ne 200 ]]; then
              echo "::error::Failed to fetch PR details. HTTP Status: $PR_HTTP_CODE"
              echo "Response: $PR_DETAILS"
              # SHOULD_RUN remains "false"
            else
              echo "PR Details fetched successfully."
              PR_HEAD_SHA=$(echo "$PR_DETAILS" | jq -r .head.sha)
              PR_HEAD_REF=$(echo "$PR_DETAILS" | jq -r .head.ref) 
              PR_NUMBER="${{ github.event.issue.number }}"

              if [ -z "$PR_HEAD_SHA" ] || [ "$PR_HEAD_SHA" == "null" ] || [ -z "$PR_HEAD_REF" ] || [ "$PR_HEAD_REF" == "null" ] || [ -z "$PR_NUMBER" ]; then
                echo "::error::Could not extract required PR details (SHA, Ref, or Number) from API response."
                echo "SHA: $PR_HEAD_SHA, Ref: $PR_HEAD_REF, Number: $PR_NUMBER"
                echo "Full Details: $PR_DETAILS"
                # SHOULD_RUN remains "false"
              else
                SHOULD_RUN="true" # All good, set to run
                echo "PR Number: $PR_NUMBER"
                echo "PR Head SHA: $PR_HEAD_SHA"
                echo "PR Head Ref: $PR_HEAD_REF"
                echo "pr_number=${PR_NUMBER}" >> $GITHUB_OUTPUT
                echo "pr_head_sha=${PR_HEAD_SHA}" >> $GITHUB_OUTPUT
                echo "pr_head_ref=${PR_HEAD_REF}" >> $GITHUB_OUTPUT
              fi
            fi
          else
            echo "Comment is not a valid re-validation command or commenter ('$COMMENTER_LOGIN') is not authorized (expected '$AUTHORIZED_ACTOR')."
            # SHOULD_RUN remains "false"
          fi
          echo "should_run_validation=${SHOULD_RUN}" >> $GITHUB_OUTPUT

  prepare_run_context:
    name: 0.B Prepare Run Context
    runs-on: ubuntu-latest
    needs: [trigger_gatekeeper] # Waits for gatekeeper; gatekeeper is skipped for PR events.
    if: always() # This job itself always tries to run after trigger_gatekeeper (or its skip)
    outputs:
      run_validation: ${{ steps.gather_info.outputs.run_validation }}
      head_sha: ${{ steps.gather_info.outputs.head_sha }}
      head_ref: ${{ steps.gather_info.outputs.head_ref }}
      pr_number: ${{ steps.gather_info.outputs.pr_number }}
    steps:
      - name: Gather PR Information and Decide to Run
        id: gather_info
        run: |
          RUN_VALIDATION="false" # Default
          HEAD_SHA=""
          HEAD_REF=""
          PR_NUMBER=""

          echo "Event name: ${{ github.event_name }}"
          echo "Trigger Gatekeeper result: ${{ needs.trigger_gatekeeper.result }}"
          echo "Trigger Gatekeeper should_run_validation output: ${{ needs.trigger_gatekeeper.outputs.should_run_validation }}"

          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "Event is pull_request. Setting run_validation to true."
            RUN_VALIDATION="true"
            HEAD_SHA="${{ github.event.pull_request.head.sha }}"
            HEAD_REF="${{ github.head_ref }}" # For PRs, github.head_ref is the source branch name
            PR_NUMBER="${{ github.event.number }}" # For PRs, github.event.number is the PR number
          elif [ "${{ github.event_name }}" == "issue_comment" ]; then
            # Only proceed if trigger_gatekeeper ran successfully and approved
            if [ "${{ needs.trigger_gatekeeper.result }}" == "success" ] && \
               [ "${{ needs.trigger_gatekeeper.outputs.should_run_validation }}" == "true" ]; then
              echo "Event is issue_comment and trigger_gatekeeper approved. Setting run_validation to true."
              RUN_VALIDATION="true"
              HEAD_SHA="${{ needs.trigger_gatekeeper.outputs.pr_head_sha }}"
              HEAD_REF="${{ needs.trigger_gatekeeper.outputs.pr_head_ref }}"
              PR_NUMBER="${{ needs.trigger_gatekeeper.outputs.pr_number }}"
            else
              echo "Event is issue_comment, but trigger_gatekeeper did not approve or was skipped/failed. Validation will not run."
            fi
          else
            echo "::warning::Unknown event type: ${{ github.event_name }}. Validation will not run based on event type."
          fi
          
          # Final check for critical info if validation is supposed to run
          if [ "$RUN_VALIDATION" == "true" ]; then
            if [ -z "$HEAD_SHA" ] || [ "$HEAD_SHA" == "null" ] || \
               [ -z "$HEAD_REF" ] || [ "$HEAD_REF" == "null" ] || \
               [ -z "$PR_NUMBER" ] || [ "$PR_NUMBER" == "null" ]; then
              echo "::error::RUN_VALIDATION is true, but required PR info (SHA, Ref, or Number) is missing or null."
              echo "SHA: '$HEAD_SHA', Ref: '$HEAD_REF', Number: '$PR_NUMBER'"
              RUN_VALIDATION="false" # Prevent further jobs from running if info is bad
            fi
          fi
          
          echo "Final decision: run_validation=${RUN_VALIDATION}"
          echo "run_validation=${RUN_VALIDATION}" >> $GITHUB_OUTPUT
          # Only output other vars if we are actually running validation
          if [ "$RUN_VALIDATION" == "true" ]; then
            echo "head_sha=${HEAD_SHA}" >> $GITHUB_OUTPUT
            echo "head_ref=${HEAD_REF}" >> $GITHUB_OUTPUT
            echo "pr_number=${PR_NUMBER}" >> $GITHUB_OUTPUT
          fi

  initial_checks:
    name: 1. Initial PR Validations
    needs: [prepare_run_context]
    if: >
      needs.prepare_run_context.outputs.run_validation == 'true' &&
      startsWith(needs.prepare_run_context.outputs.head_ref, 'feat/gen-')
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      tool_directive: ${{ steps.extract_directive.outputs.tool_directive }}
      pattern_check_passed: ${{ steps.check_patterns.outputs.check_passed }}
      path_validation_passed: ${{ steps.validate_paths.outputs.validation_passed }}
      invalid_files_list: ${{ steps.validate_paths.outputs.invalid_files_list }}
      analysis_succeeded: ${{ steps.analyze_name.outputs.analysis_succeeded }}
      ai_analysis_score: ${{ steps.analyze_name.outputs.score }}
      ai_analysis_is_typo: ${{ steps.analyze_name.outputs.is_typo }}
      ai_analysis_suggestions_json: ${{ steps.analyze_name.outputs.suggestions }}
      ai_analysis_reasoning: ${{ steps.analyze_name.outputs.reasoning }}
      critical_initial_checks_passed: ${{ (steps.check_patterns.outputs.check_passed == 'true' && steps.validate_paths.outputs.validation_passed == 'true') }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.prepare_run_context.outputs.head_sha }}
          token: ${{ secrets.GITHUB_TOKEN }} # Using default GITHUB_TOKEN
          fetch-depth: 0

      - name: Extract Tool Directive
        id: extract_directive
        env:
          BRANCH_NAME_FROM_CONTEXT: ${{ needs.prepare_run_context.outputs.head_ref }}
        run: |
          BRANCH_NAME="$BRANCH_NAME_FROM_CONTEXT"
          echo "Attempting to extract directive from branch name: $BRANCH_NAME"
          if [ -z "$BRANCH_NAME" ]; then
            echo "::error::BRANCH_NAME_FROM_CONTEXT is empty (likely from prepare_run_context). Cannot extract directive."
            exit 1
          fi
          TEMP_DIRECTIVE=${BRANCH_NAME#feat/gen-}
          TOOL_DIRECTIVE=$(echo "$TEMP_DIRECTIVE" | sed 's/-[0-9]*$//')
          if [ -z "$TOOL_DIRECTIVE" ]; then 
            echo "::error::Could not extract tool directive from branch name '$BRANCH_NAME'."
            exit 1
          fi
          echo "Extracted Tool Directive: $TOOL_DIRECTIVE"
          echo "tool_directive=${TOOL_DIRECTIVE}" >> $GITHUB_OUTPUT

      - name: Check Directive Pattern
        id: check_patterns
        run: |
          TOOL_DIRECTIVE="${{ steps.extract_directive.outputs.tool_directive }}"
          JSON_PATTERN_FILE="app/api/validate-directive/_data/tool-directive-patterns.json"
          echo "DEBUG: TOOL_DIRECTIVE is '$TOOL_DIRECTIVE'"
          if [ -z "$TOOL_DIRECTIVE" ]; then
            echo "::error::TOOL_DIRECTIVE is empty from previous step. Cannot check pattern."
            echo "check_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          if [ ! -f "$JSON_PATTERN_FILE" ]; then 
            echo "::error::JSON Pattern file '$JSON_PATTERN_FILE' not found."
            echo "check_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "DEBUG: Content of $JSON_PATTERN_FILE (raw):"
          cat "$JSON_PATTERN_FILE"
          echo "--- End of raw JSON pattern file content ---"
          TEMP_CLEANED_PATTERNS_FILE=$(mktemp)
          jq -r '.prefixPatterns[], .suffixPatterns[], .complexPatterns[] // empty' "$JSON_PATTERN_FILE" | \
          awk '!/^#/ && NF {gsub(/\r$/,""); print}' > "$TEMP_CLEANED_PATTERNS_FILE"
          if [ ! -s "$TEMP_CLEANED_PATTERNS_FILE" ]; then
            echo "::warning::No active patterns found in '$JSON_PATTERN_FILE' after cleaning and jq extraction. Assuming pass."
            echo "check_passed=true" >> $GITHUB_OUTPUT
            rm "$TEMP_CLEANED_PATTERNS_FILE"
            exit 0
          fi
          echo "DEBUG: Using cleaned patterns from $TEMP_CLEANED_PATTERNS_FILE for grep:"
          cat "$TEMP_CLEANED_PATTERNS_FILE"
          echo "--- End of Cleaned Patterns for grep ---"
          if echo "$TOOL_DIRECTIVE" | grep -q -E -f "$TEMP_CLEANED_PATTERNS_FILE"; then
            echo "Directive '$TOOL_DIRECTIVE' matches an allowed pattern."
            echo "check_passed=true" >> $GITHUB_OUTPUT
          else 
            echo "::error::Directive '$TOOL_DIRECTIVE' does not match any allowed patterns in '$JSON_PATTERN_FILE'."
            echo "check_passed=false" >> $GITHUB_OUTPUT
            exit 1 
          fi
          rm "$TEMP_CLEANED_PATTERNS_FILE"

      - name: Analyze Directive Name (AI Check)
        id: analyze_name
        if: steps.check_patterns.outputs.check_passed == 'true'
        continue-on-error: true
        env:
          APP_URL: ${{ secrets.APP_URL || 'https://online-everything-tool.com' }}
        run: |
          TOOL_DIRECTIVE="${{ steps.extract_directive.outputs.tool_directive }}"
          CLEANED_APP_URL=$(echo "${APP_URL}" | sed 's:/*$::')
          API_ENDPOINT="${CLEANED_APP_URL}/api/analyze-directive-name"
          EXISTING_DIRECTIVES_JSON='[]' 
          GENERATIVE_DESC_TEXT="Function related to ${TOOL_DIRECTIVE//-/ }"
          echo "Attempting AI Analysis API call to: $API_ENDPOINT for directive: $TOOL_DIRECTIVE"
          HTTP_STATUS=$(curl -L --max-redirs 3 -s -w "%{http_code}" -X POST "$API_ENDPOINT" \
            -H "Content-Type: application/json" \
            -d "{
                  \"proposedDirective\": \"$TOOL_DIRECTIVE\",
                  \"existingDirectives\": $EXISTING_DIRECTIVES_JSON,
                  \"generativeDescription\": \"$GENERATIVE_DESC_TEXT\"
                }" \
            -o response.json)
          echo "AI Analysis API HTTP Status (after potential redirects): $HTTP_STATUS"
          ANALYSIS_SUCCEEDED_FLAG="false"; SCORE_VAL="N/A"; IS_TYPO_VAL="N/A"; SUGGESTIONS_JSON_STR="[]"; REASONING_TEXT="Analysis could not be performed."
          if [[ "$HTTP_STATUS" -ge 200 && "$HTTP_STATUS" -lt 300 ]] && jq -e . response.json > /dev/null 2>&1; then
             echo "AI Analysis API call successful and response is valid JSON."
             SCORE_VAL=$(jq -r '.score // 0.5' response.json)
             IS_TYPO_VAL=$(jq -r '.is_likely_typo // false' response.json)
             SUGGESTIONS_JSON_STR=$(jq -c '.suggestions // []' response.json) 
             REASONING_TEXT=$(jq -r '.reasoning // "Analysis incomplete."' response.json)
             ANALYSIS_SUCCEEDED_FLAG="true"
          else
             echo "::warning::AI Analysis API call failed or returned invalid JSON (HTTP Status: $HTTP_STATUS). Analysis results will be marked as N/A."
          fi
          echo "analysis_succeeded=$ANALYSIS_SUCCEEDED_FLAG" >> $GITHUB_OUTPUT
          echo "score=$SCORE_VAL" >> $GITHUB_OUTPUT
          echo "is_typo=$IS_TYPO_VAL" >> $GITHUB_OUTPUT
          echo "suggestions=$SUGGESTIONS_JSON_STR" >> $GITHUB_OUTPUT
          {
            echo "reasoning<<EOF_REASONING"
            echo "$REASONING_TEXT"
            echo "EOF_REASONING"
          } >> $GITHUB_OUTPUT

      - name: Validate Changed File Paths
        id: validate_paths
        if: steps.check_patterns.outputs.check_passed == 'true'
        env:
          TOOL_DIRECTIVE: ${{ steps.extract_directive.outputs.tool_directive }}
        run: |
          if [ -z "$TOOL_DIRECTIVE" ]; then 
            echo "::error::TOOL_DIRECTIVE not set for path validation."
            echo "validation_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          git fetch origin main --depth=1 
          BASE_SHA=$(git merge-base HEAD origin/main)
          if [ -z "$BASE_SHA" ]; then 
            echo "::error::Could not determine merge base with main branch."
            echo "validation_passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          CHANGED_FILES_WITH_STATUS=$(git diff --name-status $BASE_SHA HEAD)
          if [ -z "$CHANGED_FILES_WITH_STATUS" ]; then 
            echo "No files changed compared to main. Assuming pass for path validation."
            echo "validation_passed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          ALLOWED_FOLDER_PATTERN="^app/tool/${TOOL_DIRECTIVE}/"
          INVALID_FILES_FOUND=""
          ALL_PATHS_VALID=true
          echo "Validating changed file paths against pattern: $ALLOWED_FOLDER_PATTERN"
          echo "Changed files (Status Path):"
          echo "$CHANGED_FILES_WITH_STATUS"
          echo "$CHANGED_FILES_WITH_STATUS" | while IFS=$'\t' read -r status filepath; do
            if [ -z "$filepath" ]; then continue; fi
            if [[ "$status" == "A" || "$status" == "M" || "$status" == "C" || "$status" == "R" ]]; then 
              actual_path_to_check=$filepath
              if [[ "$status" == "R"* ]]; then 
                  echo "Rename detected, checking path: $filepath"
              fi
              if [[ ! "$actual_path_to_check" =~ $ALLOWED_FOLDER_PATTERN ]]; then
                echo "::error file=$actual_path_to_check::Invalid path. File status: $status. Must be within '$ALLOWED_FOLDER_PATTERN'."
                INVALID_FILES_FOUND="${INVALID_FILES_FOUND}${actual_path_to_check} (Status: ${status})\n"
                ALL_PATHS_VALID=false
              else
                echo "Valid path: $actual_path_to_check (Status: $status)"
              fi
            else
              echo "Skipping strict path validation for file with status '$status': $filepath"
            fi
          done
          if $ALL_PATHS_VALID; then
            echo "validation_passed=true" >> $GITHUB_OUTPUT
          else
            echo "validation_passed=false" >> $GITHUB_OUTPUT
            INVALID_FILES_ESCAPED="${INVALID_FILES_FOUND//'%'/'%25'}"
            INVALID_FILES_ESCAPED="${INVALID_FILES_ESCAPED//$'\n'/'%0A'}"
            INVALID_FILES_ESCAPED="${INVALID_FILES_ESCAPED//$'\r'/'%0D'}"
            echo "invalid_files_list=${INVALID_FILES_ESCAPED}" >> $GITHUB_OUTPUT
            exit 1
          fi

  build_and_run_douglas_checker:
    name: 2. Build Tool & Run Douglas Ethos Check
    needs: [prepare_run_context, initial_checks]
    if: needs.initial_checks.result == 'success' && needs.initial_checks.outputs.critical_initial_checks_passed == 'true' && github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      douglas_check_step_outcome: ${{ steps.douglas_checker_run.outcome }}
      imgur_screenshot_url: ${{ steps.upload_to_imgur.outputs.image_url || '' }}
      lint_errors_captured_for_ai: ${{ steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai || 'false' }} # Ensure this output is passed up
    steps:
      - name: Checkout OET Code (PR branch)
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.prepare_run_context.outputs.head_sha }}
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22.x'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install OET Dependencies
        run: npm ci

      - name: Prepare for Static Build (Isolate New Tool)
        env:
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "Isolating tool: $TOOL_DIRECTIVE for static check"
          if [ -z "$TOOL_DIRECTIVE" ]; then
            echo "::error::Tool directive not received from initial_checks job. Cannot prune."
            exit 1
          fi
          echo "Removing app/api..."
          rm -rf app/api || echo "No app/api directory to remove or removal failed (continuing)."
          if [ -d "app/tool" ]; then
            echo "Removing other tool directories from app/tool/ ..."
            cd app/tool
            ls -d */ 2>/dev/null | grep -v -E "^(${TOOL_DIRECTIVE}/|_components/|_hooks/)$" | xargs -r rm -rf
            cd ../.. 
          else
            echo "app/tool directory not found, skipping tool pruning."
          fi
          echo "Project structure pruned for static check."

      - name: Build OET for Static Export (and check for lint issues)
        id: build_oet
        env:
          NEXT_OUTPUT_MODE: export
        run: |
          echo "Attempting static build with NEXT_OUTPUT_MODE=${NEXT_OUTPUT_MODE}..."
          BUILD_LOG_FILE_PATH="${{ runner.temp }}/build_output.log"
          echo "Running: npm run build (output will be in $BUILD_LOG_FILE_PATH and then echoed)"
          set +e 
          npm run build > "$BUILD_LOG_FILE_PATH" 2>&1
          BUILD_EXIT_CODE=$? 
          set -e 
          echo "npm run build exited with code: $BUILD_EXIT_CODE" 
          echo "--- Start of Build Output (from $BUILD_LOG_FILE_PATH) ---"
          if [ -f "$BUILD_LOG_FILE_PATH" ]; then
            cat "$BUILD_LOG_FILE_PATH"
          else
            echo "ERROR: Build log file $BUILD_LOG_FILE_PATH not found!"
          fi
          echo "--- End of Build Output ---"
          if [ "$BUILD_EXIT_CODE" -ne 0 ]; then
            echo "build_command_failed=true" >> $GITHUB_OUTPUT
            echo "::warning::'npm run build' command failed with exit code $BUILD_EXIT_CODE."
          else
            echo "build_command_failed=false" >> $GITHUB_OUTPUT
            echo "'npm run build' command succeeded."
          fi
          if [ -d "out" ]; then
            echo "Build output directory 'out' found."
            echo "build_succeeded_structurally=true" >> $GITHUB_OUTPUT
          else
            echo "::error::Build output directory 'out' not found."
            echo "build_succeeded_structurally=false" >> $GITHUB_OUTPUT
            if [ "$BUILD_EXIT_CODE" -eq 0 ]; then 
                echo "build_command_failed=true" >> $GITHUB_OUTPUT 
                echo "::error::'out' dir missing despite npm build exit code 0. Marking as command failed."
            fi
          fi
          echo "build_log_path=$BUILD_LOG_FILE_PATH" >> $GITHUB_OUTPUT

      - name: Capture Lint Output and Changed Files for AI Fixer
        id: capture_for_ai_fix
        if: steps.build_oet.outputs.build_command_failed == 'true'
        env:
          TOOL_DIRECTIVE_PATH: app/tool/${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "--- Start of capture_for_ai_fix step ---"
          echo "Condition for this step (build_command_failed == 'true') was met."
          BUILD_LOG_FILE="${{ steps.build_oet.outputs.build_log_path }}"
          LINT_DATA_DIR="${{ runner.temp }}/lint-data-for-artifact"
          mkdir -p "$LINT_DATA_DIR"
          LINT_ERRORS_FILE="$LINT_DATA_DIR/lint_errors.txt"
          FILES_TO_CHECK_FILE="$LINT_DATA_DIR/files_to_check.txt"
          LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG="false" 
          if [ -f "$BUILD_LOG_FILE" ]; then
            echo "Build log file found: $BUILD_LOG_FILE"
            if grep -q -E "Failed to compile.|requires a value, but a value was not provided" "$BUILD_LOG_FILE"; then
              echo "MATCHED: 'Failed to compile.' or similar found in build log."
              cp "$BUILD_LOG_FILE" "$LINT_ERRORS_FILE"
              echo "Copied build log to $LINT_ERRORS_FILE"
              echo "Identifying newly added .ts/.tsx files in '$TOOL_DIRECTIVE_PATH' for potential AI fix..."
              find "$TOOL_DIRECTIVE_PATH" \( -name "*.ts" -o -name "*.tsx" \) -type f > "$FILES_TO_CHECK_FILE"
              echo "Result of find command (content of $FILES_TO_CHECK_FILE):"
              cat "$FILES_TO_CHECK_FILE"
              if [ -s "$FILES_TO_CHECK_FILE" ]; then
                echo "Found .ts/.tsx files in the tool directory. Setting LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG to true."
                LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG="true"
              else
                echo "::warning::Build failed with lint-like errors, but NO relevant .ts/.tsx files were found in '$TOOL_DIRECTIVE_PATH'. AI fix will NOT be attempted for this run."
              fi
            else
              echo "NO MATCH: 'Failed to compile.' or similar NOT found in build log. Not treating as lint failure for AI fix."
            fi
          else
            echo "::warning::Build output log ($BUILD_LOG_FILE) not found. Cannot extract lint errors."
          fi
          echo "Final LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG value before setting output: $LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG"
          echo "lint_errors_captured_for_ai=$LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG" >> $GITHUB_OUTPUT
          echo "--- End of capture_for_ai_fix step ---"

      - name: Upload Lint Failure Artifact for AI Fixer
        if: steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: lint-failure-data-${{ needs.prepare_run_context.outputs.head_sha }}
          path: ${{ runner.temp }}/lint-data-for-artifact/
          if-no-files-found: warn

      - name: Serve Static Output Locally
        id: serve_static
        if: steps.build_oet.outputs.build_succeeded_structurally == 'true' && steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai != 'true'
        run: |
          echo "Starting static server for 'out' directory on port 3001..."
          if sudo fuser 3001/tcp > /dev/null 2>&1; then
            echo "Port 3001 is in use. Attempting to kill process..."
            sudo fuser -k 3001/tcp || echo "Failed to kill process on port 3001, or it was already free."
            sleep 2 
          fi
          npx serve out -l 3001 & 
          SERVER_PID=$!
          echo "Server PID: $SERVER_PID"
          echo "server_pid=$SERVER_PID" >> $GITHUB_OUTPUT
          echo "Local server URL: http://localhost:3001"
          echo "Waiting for server on port 3001..."
          timeout 30s bash -c 'until curl -sSf http://localhost:3001 > /dev/null; do echo -n "."; sleep 1; done' \
          || (echo "::error::Local server (npx serve) did not start on port 3001 in time." && (sudo kill -9 $SERVER_PID || true) && exit 1)
          echo "Server is up!"
        continue-on-error: true

      - name: Clone Douglas Checker
        if: steps.serve_static.outcome == 'success'
        run: |
          echo "Cloning Douglas checker..."
          git clone https://github.com/Online-Everything-Tool/douglas.git ./douglas-checker
          if [ ! -d "./douglas-checker" ]; then
            echo "::error::Failed to clone Douglas checker repository."
            exit 1
          fi

      - name: Install Douglas Checker Dependencies
        if: steps.serve_static.outcome == 'success'
        working-directory: ./douglas-checker
        run: |
          echo "Installing Douglas dependencies..."
          if [ -f "package-lock.json" ]; then
            npm ci
          else
            npm install
          fi

      - name: Run Douglas Ethos Check
        id: douglas_checker_run
        if: steps.serve_static.outcome == 'success'
        working-directory: ./douglas-checker
        env:
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "Running Douglas check for tool: $TOOL_DIRECTIVE"
          TARGET_URL="http://localhost:3001/tool/$TOOL_DIRECTIVE/"
          SUMMARY_FILE_PATH="$RUNNER_TEMP/douglas_summary.md"
          SCREENSHOT_FILE_PATH="$RUNNER_TEMP/douglas_screenshot.png"
          if [ ! -f "./dist/check-tool.js" ]; then
            echo "Douglas checker not compiled. Attempting to compile..."
            npx tsc || (echo "::error::Failed to compile Douglas checker." && exit 1)
            if [ ! -f "./dist/check-tool.js" ]; then
              echo "::error::Douglas checker (dist/check-tool.js) still not found after compile attempt." && exit 1
            fi
          fi
          COMMAND_ARGS=("$TARGET_URL" --outputSummaryFile "$SUMMARY_FILE_PATH" --screenshotPath "$SCREENSHOT_FILE_PATH")
          echo "Executing: node ./dist/check-tool.js ${COMMAND_ARGS[@]}"
          node ./dist/check-tool.js "${COMMAND_ARGS[@]}"
        continue-on-error: true

      - name: Upload Screenshot to Imgur
        id: upload_to_imgur
        if: always() && steps.douglas_checker_run.outcome != 'skipped' && steps.serve_static.outcome == 'success'
        env:
          IMGUR_CLIENT_ID: ${{ secrets.IMGUR_CLIENT_ID }}
        run: |
          SCREENSHOT_FILE="$RUNNER_TEMP/douglas_screenshot.png"
          IMAGE_URL=""
          PR_NUM_FOR_TITLE="${{ needs.prepare_run_context.outputs.pr_number }}"
          if [ -f "$SCREENSHOT_FILE" ]; then
            if [ -z "$IMGUR_CLIENT_ID" ]; then
              echo "::warning::IMGUR_CLIENT_ID secret not set. Cannot upload screenshot to Imgur."
            else
              echo "Uploading $SCREENSHOT_FILE to Imgur..."
              RESPONSE=$(curl -s -X POST \
                -H "Authorization: Client-ID $IMGUR_CLIENT_ID" \
                -F "image=@$SCREENSHOT_FILE" \
                -F "type=file" \
                -F "title=Douglas Check for PR $PR_NUM_FOR_TITLE - ${{ needs.initial_checks.outputs.tool_directive }}" \
                -F "description=Automated ethos check by Douglas for OET PR $PR_NUM_FOR_TITLE on tool ${{ needs.initial_checks.outputs.tool_directive }}. Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
                https://api.imgur.com/3/image)
              echo "Imgur API Response: $RESPONSE"
              UPLOAD_SUCCESS=$(echo "$RESPONSE" | jq -r .success)
              if [ "$UPLOAD_SUCCESS" = "true" ]; then
                IMAGE_URL=$(echo "$RESPONSE" | jq -r .data.link)
                echo "Screenshot uploaded to Imgur: $IMAGE_URL"
              else
                ERROR_MSG=$(echo "$RESPONSE" | jq -r .data.error)
                echo "::warning::Failed to upload screenshot to Imgur. Error: $ERROR_MSG"
              fi
            fi
          else
            echo "::warning::Screenshot file $SCREENSHOT_FILE not found. Cannot upload to Imgur."
          fi
          echo "image_url=$IMAGE_URL" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Upload Douglas Summary Artifact
        if: always() && steps.serve_static.outcome == 'success' && steps.douglas_checker_run.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: douglas-summary-${{ github.run_id }}
          path: ${{ runner.temp }}/douglas_summary.md
          if-no-files-found: warn

      - name: Upload Douglas Screenshot Artifact (as fallback)
        if: always() && steps.serve_static.outcome == 'success' && steps.douglas_checker_run.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: douglas-screenshot-${{ github.run_id }}
          path: ${{ runner.temp }}/douglas_screenshot.png
          if-no-files-found: warn

      - name: Kill Static Server
        if: always() && steps.serve_static.outcome == 'success' && steps.serve_static.outputs.server_pid
        run: |
          echo "Attempting to kill static server PID: ${{ steps.serve_static.outputs.server_pid }}..."
          (sudo kill -9 ${{ steps.serve_static.outputs.server_pid }} || echo "Kill failed, server might be already stopped.")
          if sudo fuser 3001/tcp > /dev/null 2>&1; then
             echo "Port 3001 still in use after PID kill, attempting fuser kill..."
             sudo fuser -k 3001/tcp || echo "fuser kill also failed or port now free."
          else
             echo "Port 3001 is free."
          fi

  report_pr_status:
    name: 3. Report PR Validation Status
    needs:
      - prepare_run_context
      - initial_checks
      - build_and_run_douglas_checker
    # This job always runs if not dependabot, to report status or skips
    if: always() && github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write 
      actions: read 
    steps:
      - name: Download Douglas Summary Artifact
        id: download_summary
        if: needs.build_and_run_douglas_checker.result != 'skipped' && needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome != 'skipped'
        uses: actions/download-artifact@v4
        with:
          name: douglas-summary-${{ github.run_id }}
          path: ${{ runner.temp }}/douglas-artifacts/summary
        continue-on-error: true

      - name: Read Douglas Summary Content
        id: read_summary
        if: steps.download_summary.outcome == 'success' # Only if download was attempted and succeeded
        run: |
          SUMMARY_FILE="${{ runner.temp }}/douglas-artifacts/summary/douglas_summary.md"
          if [ ! -f "$SUMMARY_FILE" ]; then
            echo "Douglas summary file not found at $SUMMARY_FILE after download. Setting empty summary."
            echo "summary_markdown=" >> $GITHUB_OUTPUT
            exit 0
          fi
          SUMMARY_CONTENT=$(cat "$SUMMARY_FILE")
          SUMMARY_CONTENT="${SUMMARY_CONTENT//'%'/'%25'}" 
          SUMMARY_CONTENT="${SUMMARY_CONTENT//$'\n'/'%0A'}"
          SUMMARY_CONTENT="${SUMMARY_CONTENT//$'\r'/'%0D'}"
          echo "summary_markdown=${SUMMARY_CONTENT}" >> $GITHUB_OUTPUT
        shell: bash
        continue-on-error: true

      - name: Construct and Post PR Comment
        id: post_comment
        # Only post if the main validation logic was intended to run
        if: needs.prepare_run_context.outputs.run_validation == 'true' || github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          PR_NUMBER_FROM_CONTEXT: ${{ needs.prepare_run_context.outputs.pr_number }}
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }} # Will be empty if initial_checks skipped
          INITIAL_CHECKS_JOB_RESULT: ${{ needs.initial_checks.result }}
          PATH_VALIDATION_PASSED: ${{ needs.initial_checks.outputs.path_validation_passed }}
          INVALID_FILES_LIST: ${{ needs.initial_checks.outputs.invalid_files_list }}
          AI_ANALYSIS_SUCCEEDED: ${{ needs.initial_checks.outputs.analysis_succeeded }}
          AI_SCORE: ${{ needs.initial_checks.outputs.ai_analysis_score }}
          AI_IS_TYPO: ${{ needs.initial_checks.outputs.ai_analysis_is_typo }}
          AI_SUGGESTIONS_JSON: ${{ needs.initial_checks.outputs.ai_analysis_suggestions_json }}
          AI_REASONING: ${{ needs.initial_checks.outputs.ai_analysis_reasoning }}
          BUILD_DOUGLAS_JOB_RESULT: ${{ needs.build_and_run_douglas_checker.result }}
          LINT_ERRORS_CAPTURED_FOR_AI: ${{ needs.build_and_run_douglas_checker.outputs.lint_errors_captured_for_ai || 'false' }}
          DOUGLAS_CHECK_STEP_OUTCOME: ${{ needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome || 'skipped' }}
          IMGUR_SCREENSHOT_URL: ${{ needs.build_and_run_douglas_checker.outputs.imgur_screenshot_url }}
          DOUGLAS_SUMMARY_MD: ${{ steps.read_summary.outputs.summary_markdown || 'Douglas summary not available or check was skipped.' }}
          ACTION_RUN_URL: 'https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}'
          IS_COMMENT_TRIGGERED_RUN: ${{ github.event_name == 'issue_comment' && needs.trigger_gatekeeper.outputs.should_run_validation == 'true' }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumberFromContext = process.env.PR_NUMBER_FROM_CONTEXT;
            const eventName = context.eventName;
            let issue_number_str = "";

            if (eventName === 'pull_request') {
              issue_number_str = context.payload.pull_request.number.toString();
            } else if (eventName === 'issue_comment' && prNumberFromContext) {
              issue_number_str = prNumberFromContext;
            }

            if (!issue_number_str) {
              core.info("PR Number not determinable for this event. Skipping comment.");
              return;
            }
            const issue_number = parseInt(issue_number_str, 10);
            if (isNaN(issue_number)) {
              core.setFailed(`Parsed PR Number is NaN from string: '${issue_number_str}'.`);
              return;
            }

            const isCommentTriggeredRun = process.env.IS_COMMENT_TRIGGERED_RUN === 'true';
            const initialChecksResult = process.env.INITIAL_CHECKS_JOB_RESULT;
            const buildDouglasJobResult = process.env.BUILD_DOUGLAS_JOB_RESULT;
            const toolDirective = process.env.TOOL_DIRECTIVE || "UnknownTool"; // Default if initial_checks skipped
            const actionRunUrl = `${process.env.ACTION_RUN_URL}?pr=${issue_number}`;
            let commentBody = ``;

            if (isCommentTriggeredRun) {
              commentBody += `## 🤖 OET Tool PR Re-Validation Status (after AI Fixes) for \`${toolDirective}\`\n\n`;
            } else {
              commentBody += `## 🤖 OET Tool PR Validation Status for \`${toolDirective}\`\n\n`;
            }

            // Section 1: Initial PR Validations
            commentBody += `### 1. Initial PR Validations\n`;
            // Check if initial_checks job was even supposed to run based on its own 'if' condition
            const initialChecksShouldHaveRun = (eventName === 'pull_request' && process.env.TOOL_DIRECTIVE !== "UnknownTool") || isCommentTriggeredRun;

            if (!initialChecksShouldHaveRun && initialChecksResult === 'skipped') {
                 commentBody += `🟡 Initial validations were skipped (e.g., branch name pattern not matched for PR, or comment trigger not approved). See [Action logs](${actionRunUrl}) for details.\n`;
            } else if (initialChecksResult === 'success') {
              commentBody += `✅ **Initial Validations Passed!**\n`;
              if (process.env.PATH_VALIDATION_PASSED === 'true') {
                commentBody += `  - All changed files are within the allowed directory for \`${toolDirective}\`.\n`;
              } else if (process.env.PATH_VALIDATION_PASSED === 'false') {
                // This case should ideally be covered by initialChecksResult === 'failure'
                const invalidFiles = (process.env.INVALID_FILES_LIST || "List unavailable.").replace(/%0A/g, '\n    - ').replace(/%0D/g, '');
                commentBody += `  - **Path Validation Failed:** Files changed outside allowed directory. Invalid files:\n    - ${invalidFiles}\n`;
              }
              commentBody += `\n  **🤖 AI Directive Name Analysis:**\n`;
              if (process.env.AI_ANALYSIS_SUCCEEDED === 'true') {
                commentBody += `    - Score: **${process.env.AI_SCORE}**\n`;
                commentBody += `    - Likely Typo: ${process.env.AI_IS_TYPO === 'true' ? '**Yes** ❗' : 'No'}\n`;
                let reasoning = (process.env.AI_REASONING || "No reasoning provided.").replace(/%0A/g, '\n        ');
                commentBody += `    - Reasoning:\n        ${reasoning}\n`;
                try {
                  const suggestions = JSON.parse(process.env.AI_SUGGESTIONS_JSON || '[]');
                  if (suggestions.length > 0) {
                    commentBody += `    - Suggestions: ${suggestions.map(s => `\`${s}\``).join(', ')}\n`;
                  }
                } catch (e) { console.warn("Could not parse AI suggestions JSON."); }
              } else {
                commentBody += `    - ⚠️ AI name analysis could not be performed or API call failed.\n`;
              }
            } else if (initialChecksResult === 'failure') {
              commentBody += `🚨 **Initial Validations FAILED!**\n`;
              if (process.env.PATH_VALIDATION_PASSED === 'false') { // Check if path validation was the cause
                const invalidFiles = (process.env.INVALID_FILES_LIST || "List unavailable.").replace(/%0A/g, '\n    - ').replace(/%0D/g, '');
                commentBody += `  - **Path Validation Failed:** Files changed outside allowed directory. Invalid files:\n    - ${invalidFiles}\n`;
              } else { // Other failure in initial_checks
                commentBody += `  - One or more initial checks failed. See logs for details (e.g., directive pattern).\n`;
              }
            } else { // Handles 'cancelled' or other unexpected results like 'skipped' when it should have run
               commentBody += `🟡 Initial validations status: ${initialChecksResult}. See [Action logs](${actionRunUrl}).\n`;
            }
            commentBody += "\n---\n";

            // Section 2: Local Build & Douglas Ethos Check
            commentBody += `### 2. Local Build & Douglas Ethos Check\n`;
            const lintErrorsCapturedForAI = process.env.LINT_ERRORS_CAPTURED_FOR_AI === 'true';
            const douglasCheckStepOutcome = process.env.DOUGLAS_CHECK_STEP_OUTCOME;

            if (initialChecksResult !== 'success') {
                commentBody += `🟡 Build & Douglas checks skipped due to initial validation status: ${initialChecksResult}.\n`;
            } else if (lintErrorsCapturedForAI && !isCommentTriggeredRun) {
              commentBody += `🟡 **Build/Lint Failed.** An AI Lint Fixer workflow should be triggered. It will post a \`/revalidate-ai-fixes\` comment to re-run these checks if it makes changes.\n`;
              commentBody += `   Douglas Ethos Check was skipped in this run due to the build failure.\n`;
            } else if (buildDouglasJobResult === 'skipped') {
              commentBody += `🟡 Local build and Douglas Ethos Check job were skipped (likely due to its own 'if' condition not met).\n`;
            } else if (buildDouglasJobResult === 'failure') {
              commentBody += `🚨 **Local Static Build FAILED!**\n`;
              if (isCommentTriggeredRun) {
                commentBody += `   This was a re-validation run after AI fixes, but the build still failed.\n`;
              }
              commentBody += `   Review [Action logs for Build & Douglas Job](${actionRunUrl}) for build failure details.\n`;
            } else if (buildDouglasJobResult === 'success') {
              commentBody += `✅ **Local Static Build Successful.**\n`;
              if (douglasCheckStepOutcome === 'success') {
                commentBody += `✅ **Douglas Ethos Check Passed!**\n`;
              } else if (douglasCheckStepOutcome === 'skipped') {
                commentBody += `🟡 Douglas Ethos Check was skipped (e.g., static server did not start, or its 'if' condition not met).\n`;
              } else { 
                commentBody += `🚨 **Douglas Ethos Check FAILED or had issues!** (Outcome: ${douglasCheckStepOutcome})\n`;
              }
              const douglasSummary = (process.env.DOUGLAS_SUMMARY_MD || "").replace(/%0A/g, '\n').replace(/%0D/g, '');
              if (douglasSummary.trim() !== "" && douglasSummary.trim() !== "Douglas summary not available or check was skipped.") {
                  commentBody += `\n${douglasSummary}\n`; 
              }
              const imgurUrl = process.env.IMGUR_SCREENSHOT_URL;
              if (imgurUrl) {
                commentBody += `\n   **Douglas's View (Screenshot):**\n   ![Douglas Screenshot](${imgurUrl})\n   (Direct link: ${imgurUrl})\n\n`;
              } else if (douglasCheckStepOutcome && douglasCheckStepOutcome !== 'skipped') {
                commentBody += `   (Screenshot not uploaded to Imgur or not found. View artifact [on Action run page](${actionRunUrl}))\n`;
              }
            } else { // Other buildDouglasJobResult like 'cancelled'
                commentBody += `🟡 Build & Douglas checks status: ${buildDouglasJobResult}. See [Action logs](${actionRunUrl}).\n`;
            }
            commentBody += "\n---\n";

            // Section 3: Next Steps
            commentBody += `### 3. Next Steps\n`;
            const currentRunPassedAllCritical = initialChecksResult === 'success' && 
                                             buildDouglasJobResult === 'success' && 
                                             douglasCheckStepOutcome === 'success';

            if (lintErrorsCapturedForAI && !isCommentTriggeredRun) {
              commentBody += `⏳ An AI Lint Fixer workflow is being triggered. Wait for its \`/revalidate-ai-fixes\` comment.\n`;
            } else if (currentRunPassedAllCritical) {
              commentBody += `✅ All checks passed for this run!\n`;
              if (isCommentTriggeredRun) {
                commentBody += `   The AI fixes appear to have resolved the prior issues.\n`;
              }
              commentBody += `⏳ A Netlify Deploy Preview should be building/updating. Its status will appear as a separate check on this PR.\n`;
              commentBody += `👍 Once ready, please test your tool thoroughly using the Deploy Preview link!\n`;
            } else {
              commentBody += `‼️ **Action Required:** One or more critical checks failed in this run. Review details above and in [Action run logs](${actionRunUrl}).\n`;
              if (isCommentTriggeredRun && initialChecksResult === 'success' && buildDouglasJobResult === 'failure') {
                commentBody += `   The AI fixes were applied, but the build still failed. Manual intervention might be needed.\n`;
              } else if (isCommentTriggeredRun && initialChecksResult === 'success' && buildDouglasJobResult === 'success' && douglasCheckStepOutcome !== 'success') {
                commentBody += `   The AI fixes were applied and build succeeded, but Douglas Ethos check found issues. Manual intervention might be needed.\n`;
              } else if (isCommentTriggeredRun) {
                commentBody += `   The AI fixes may not have been sufficient. Manual intervention might be needed.\n`;
              }
            }
            commentBody += `\n---\n*This comment is auto-generated by OET CI. For full details, see the [Action Run](${actionRunUrl}).*`;

            try {
              await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: issue_number, body: commentBody });
            } catch (e) {
              core.error(`Failed to post PR comment: ${e.message}`);
            }

      - name: Fail workflow if critical checks failed (and no AI Fix Attempted by THIS run)
        if: >
          (
            needs.prepare_run_context.outputs.run_validation == 'true' &&
            (
              needs.initial_checks.result == 'failure' ||
              (
                needs.build_and_run_douglas_checker.result == 'failure' &&
                (needs.build_and_run_douglas_checker.outputs.lint_errors_captured_for_ai || 'false') != 'true' 
              ) ||
              (
                needs.build_and_run_douglas_checker.result == 'success' &&
                (needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome || 'skipped') != 'success' &&
                (needs.build_and_run_douglas_checker.outputs.lint_errors_captured_for_ai || 'false') != 'true'
              )
            )
          )
        run: |
          echo "::error::One or more critical checks failed, and no AI Lint Fix was initiated by *this specific workflow run* to address them. Marking this workflow run as failed."
          exit 1