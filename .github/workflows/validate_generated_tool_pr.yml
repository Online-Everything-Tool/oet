name: Validate Generated Tool PR

on:
  pull_request:
    types: [opened, synchronize]
    branches: # PRs targeting these base branches
      - main

jobs:
  initial_checks:
    name: 1. Initial PR Validations
    if: >
      github.event_name == 'pull_request' &&
      startsWith(github.head_ref, 'feat/gen-') && 
      github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      contents: read

    outputs:
      pr_number: ${{ steps.set_pr_info.outputs.pr_number }}
      pr_sha: ${{ steps.set_pr_info.outputs.pr_sha }}
      head_ref: ${{ steps.set_pr_info.outputs.head_ref }} 
      tool_directive: ${{ steps.extract_directive_and_metadata.outputs.tool_directive }}
      tool_description: ${{ steps.extract_directive_and_metadata.outputs.tool_description }}
      critical_initial_checks_passed: ${{ steps.set_pr_info.outputs.should_run == 'true' && (steps.validate_paths.outputs.validation_passed == 'true' || steps.validate_paths.outcome == 'skipped') && steps.extract_directive_and_metadata.outputs.metadata_ok == 'true' }}
      path_validation_passed_output: ${{ steps.validate_paths.outputs.validation_passed }}
      invalid_files_list_output: ${{ steps.validate_paths.outputs.invalid_files_list }}
      analysis_succeeded_output: ${{ steps.analyze_name.outputs.analysis_succeeded }}
      ai_analysis_score_output: ${{ steps.analyze_name.outputs.score }}
      ai_analysis_is_typo_output: ${{ steps.analyze_name.outputs.is_typo }}
      ai_analysis_suggestions_json_output: ${{ steps.analyze_name.outputs.suggestions }}
      ai_analysis_reasoning_output: ${{ steps.analyze_name.outputs.reasoning }}

    steps:
      - name: Set PR Info 
        id: set_pr_info
        run: |
          echo "::group::Set PR Info"
          PR_NUMBER="${{ github.event.pull_request.number }}"
          HEAD_REF="${{ github.head_ref }}" 
          PR_SHA="${{ github.event.pull_request.head.sha }}"
          SHOULD_RUN="true" 
          echo "PR Number: $PR_NUMBER"
          echo "Head Ref (Branch): $HEAD_REF"
          echo "PR SHA: $PR_SHA"
          echo "pr_number=${PR_NUMBER}" >> $GITHUB_OUTPUT
          echo "head_ref=${HEAD_REF}" >> $GITHUB_OUTPUT
          echo "pr_sha=${PR_SHA}" >> $GITHUB_OUTPUT
          echo "should_run=${SHOULD_RUN}" >> $GITHUB_OUTPUT
          echo "::endgroup::"

      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.set_pr_info.outputs.pr_sha }} 
          fetch-depth: 0

      - name: Extract Tool Directive & Read Metadata Description
        id: extract_directive_and_metadata
        run: |
          BRANCH_NAME="${{ steps.set_pr_info.outputs.head_ref }}"
          TEMP_DIRECTIVE=${BRANCH_NAME#feat/gen-}
          TOOL_DIRECTIVE=$(echo "$TEMP_DIRECTIVE" | sed 's/-[0-9]*$//')
          if [ -z "$TOOL_DIRECTIVE" ]; then 
            echo "::error::Could not extract tool directive from branch name '$BRANCH_NAME'."; exit 1;
          fi
          echo "tool_directive=${TOOL_DIRECTIVE}" >> $GITHUB_OUTPUT
          METADATA_FILE_PATH="app/tool/${TOOL_DIRECTIVE}/metadata.json"
          if [ ! -f "$METADATA_FILE_PATH" ]; then
            echo "::error file=${METADATA_FILE_PATH}::Required metadata.json not found for tool '${TOOL_DIRECTIVE}'."; 
            echo "metadata_ok=false" >> $GITHUB_OUTPUT; exit 1;
          fi
          TOOL_DESCRIPTION=$(jq -r '.description // ""' "$METADATA_FILE_PATH")
          if [ -z "$TOOL_DESCRIPTION" ] || [ "$TOOL_DESCRIPTION" == "null" ]; then
            echo "::error file=${METADATA_FILE_PATH}::'description' field missing or empty in $METADATA_FILE_PATH."; 
            echo "metadata_ok=false" >> $GITHUB_OUTPUT; exit 1;
          fi
          echo "tool_description=${TOOL_DESCRIPTION}" >> $GITHUB_OUTPUT
          echo "metadata_ok=true" >> $GITHUB_OUTPUT

      - name: Analyze Directive Name (AI Check)
        if: steps.extract_directive_and_metadata.outputs.metadata_ok == 'true' && github.event.action == 'opened'
        id: analyze_name
        env:
          APP_URL: ${{ secrets.APP_URL || 'https://online-everything-tool.com' }}
        run: |
          TOOL_DIRECTIVE="${{ steps.extract_directive_and_metadata.outputs.tool_directive }}"
          TOOL_DESCRIPTION="${{ steps.extract_directive_and_metadata.outputs.tool_description }}"
          CLEANED_APP_URL=$(echo "${APP_URL}" | sed 's:/*$::')
          API_ENDPOINT="${CLEANED_APP_URL}/api/analyze-directive-name" 
          EXISTING_DIRECTIVES_JSON='[]' # In a real scenario, fetch this or read from a file
          echo "Attempting AI Analysis API call to: $API_ENDPOINT for directive: $TOOL_DIRECTIVE"
          HTTP_STATUS=$(curl -L --max-redirs 3 -s -w "%{http_code}" -X POST "$API_ENDPOINT" \
            -H "Content-Type: application/json" \
            -d "{
                  \"proposedDirective\": \"$TOOL_DIRECTIVE\",
                  \"existingDirectives\": $EXISTING_DIRECTIVES_JSON,
                  \"generativeDescription\": \"$TOOL_DESCRIPTION\"
                }" \
            -o response.json)
          ANALYSIS_SUCCEEDED_FLAG="false"; SCORE_VAL="N/A"; IS_TYPO_VAL="N/A"; SUGGESTIONS_JSON_STR="[]"; REASONING_TEXT="Analysis could not be performed."
          if [[ "$HTTP_STATUS" -ge 200 && "$HTTP_STATUS" -lt 300 ]] && jq -e . response.json > /dev/null 2>&1; then
             echo "AI Analysis API call successful and response is valid JSON."
             SCORE_VAL=$(jq -r '.score // 0.5' response.json)
             IS_TYPO_VAL=$(jq -r '.is_likely_typo // false' response.json)
             SUGGESTIONS_JSON_STR=$(jq -c '.suggestions // []' response.json) 
             REASONING_TEXT=$(jq -r '.reasoning // "Analysis incomplete."' response.json)
             ANALYSIS_SUCCEEDED_FLAG="true"
          else
             echo "::warning::AI Analysis API call failed or returned invalid JSON (HTTP Status: $HTTP_STATUS). Analysis results will be marked as N/A."
          fi
          echo "analysis_succeeded=$ANALYSIS_SUCCEEDED_FLAG" >> $GITHUB_OUTPUT
          echo "score=$SCORE_VAL" >> $GITHUB_OUTPUT
          echo "is_typo=$IS_TYPO_VAL" >> $GITHUB_OUTPUT
          echo "suggestions=$SUGGESTIONS_JSON_STR" >> $GITHUB_OUTPUT
          {
            echo "reasoning<<EOF_REASONING"
            echo "$REASONING_TEXT"
            echo "EOF_REASONING"
          } >> $GITHUB_OUTPUT

      - name: Validate Changed File Paths
        if: steps.extract_directive_and_metadata.outputs.metadata_ok == 'true' && github.event.action == 'opened'
        id: validate_paths
        env:
          TOOL_DIRECTIVE: ${{ steps.extract_directive_and_metadata.outputs.tool_directive }}
        run: |
          echo "Running path validation for 'pull_request.opened' event."    
          if [ -z "$TOOL_DIRECTIVE" ]; then 
            echo "::error::TOOL_DIRECTIVE not set for path validation."; echo "validation_passed=false" >> $GITHUB_OUTPUT; exit 1;
          fi
          BASE_SHA="${{ github.event.pull_request.base.sha }}"
          echo "Base SHA for diff (PR base): $BASE_SHA"
          echo "Current Head SHA: ${{ steps.set_pr_info.outputs.pr_sha }}"
          CHANGED_FILES_WITH_STATUS=$(git diff --name-status $BASE_SHA ${{ steps.set_pr_info.outputs.pr_sha }})
          if [ -z "$CHANGED_FILES_WITH_STATUS" ]; then 
            echo "No files changed compared to PR base. Assuming pass for path validation."; echo "validation_passed=true" >> $GITHUB_OUTPUT; exit 0;
          fi
          ALLOWED_FOLDER_PATTERN="^app/tool/${TOOL_DIRECTIVE}/"
          INVALID_FILES_FOUND=""
          ALL_PATHS_VALID=true
          echo "Validating changed file paths against pattern: $ALLOWED_FOLDER_PATTERN"
          echo "Changed files (Status Path):"; echo "$CHANGED_FILES_WITH_STATUS"
          echo "$CHANGED_FILES_WITH_STATUS" | while IFS=$'\t' read -r status filepath; do
            if [ -z "$filepath" ]; then continue; fi; actual_path_to_check=$filepath
            if [[ "$status" == "R"* ]]; then echo "Rename detected, checking new path: $filepath"; fi
            if [[ "$status" == "A" || "$status" == "M" || "$status" == "C" || "$status" == R* ]]; then
              if [[ ! "$actual_path_to_check" =~ $ALLOWED_FOLDER_PATTERN ]]; then
                echo "::error file=$actual_path_to_check::Invalid path. Status: $status. Must be within '$ALLOWED_FOLDER_PATTERN'."
                INVALID_FILES_FOUND="${INVALID_FILES_FOUND}${actual_path_to_check} (Status: ${status})\n"; ALL_PATHS_VALID=false
              else
                echo "Valid path: $actual_path_to_check (Status: $status)"
              fi
            else
              echo "Skipping strict path validation for status '$status': $filepath"
            fi
          done
          if $ALL_PATHS_VALID; then
            echo "validation_passed=true" >> $GITHUB_OUTPUT
          else
            echo "validation_passed=false" >> $GITHUB_OUTPUT
            INVALID_FILES_ESCAPED="${INVALID_FILES_FOUND//'%'/'%25'}"; INVALID_FILES_ESCAPED="${INVALID_FILES_ESCAPED//$'\n'/'%0A'}"; INVALID_FILES_ESCAPED="${INVALID_FILES_ESCAPED//$'\r'/'%0D'}"
            echo "invalid_files_list=${INVALID_FILES_ESCAPED}" >> $GITHUB_OUTPUT
          fi
  
  analyze_state_and_dependencies: # Renamed job
    name: 2. Analyze Tool State & Dependencies
    needs: initial_checks
    if: success() && needs.initial_checks.outputs.critical_initial_checks_passed == 'true'
    runs-on: ubuntu-latest
    outputs:
      dependency_action_required: ${{ steps.check_tool_info.outputs.action_required_for_npm_deps }}
      asset_action_required: ${{ steps.check_tool_info.outputs.action_required_for_assets }} 
    permissions:
      contents: read 
      actions: write 

    steps:
      - name: Checkout PR Code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.initial_checks.outputs.pr_sha }}

      - name: Check tool-generation-info.json for Dependencies and Assets
        id: check_tool_info
        env:
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }}
          TOOL_DESCRIPTION_FOR_ARTIFACT: ${{ needs.initial_checks.outputs.tool_description }}
        run: |
          set -e
          DEPS_ACTION_REQUIRED="false"
          ASSET_ACTION_REQUIRED="false"
          DEPS_ARTIFACT_UPLOAD_PATH=""
          ASSET_ARTIFACT_UPLOAD_PATH=""
          TOOL_INFO_FILE_PATH="app/tool/${TOOL_DIRECTIVE}/tool-generation-info.json"

          FOUND_NEW_DEP="false"
          NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR="[]" # Must be initialized as a valid JSON array string

          echo "--- Start: check_tool_info for ${TOOL_DIRECTIVE} (Focus on Payload Creation) ---"
          echo "Tool Info File Path: ${TOOL_INFO_FILE_PATH}"
          echo "Initial: FOUND_NEW_DEP='${FOUND_NEW_DEP}', NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR='${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}'"
          echo "---------------------------------------------"

          if [ ! -f "$TOOL_INFO_FILE_PATH" ]; then
            echo "::notice::'$TOOL_INFO_FILE_PATH' not found."
          else
            echo "Reading '$TOOL_INFO_FILE_PATH'"
            if jq -e '.identifiedDependencies? | type == "array" and length > 0' "$TOOL_INFO_FILE_PATH" > /dev/null 2>&1; then
              IDENTIFIED_DEPS_JSON_STR=$(jq -r '.identifiedDependencies | tojson' "$TOOL_INFO_FILE_PATH")
              echo "Identified Dependencies JSON from tool-info: $IDENTIFIED_DEPS_JSON_STR"

              while IFS= read -r dep_obj_json; do
                packageName=$(echo "$dep_obj_json" | jq -r '.packageName')
                echo "  Processing identified dependency: '$packageName'"
                if [ "$packageName" = "null" ] || [ -z "$packageName" ]; then
                  echo "    Skipping null or empty package name."
                  continue
                fi

                echo "    Checking if '$packageName' exists in package.json..."
                set +e
                jq -e --arg pkg "$packageName" '((.dependencies // {})[$pkg]) or ((.devDependencies // {})[$pkg])' package.json > /dev/null 2>&1
                JQ_EXIT_CODE=$?
                set -e

                if [ $JQ_EXIT_CODE -ne 0 ]; then # Package NOT found
                  echo "    '$packageName' NOT found in package.json (jq exit code: $JQ_EXIT_CODE)."
                  echo "    BEFORE append: NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR='${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}'"
                  # Ensure that dep_obj_json is valid JSON before trying to use it with --argjson
                  if ! echo "$dep_obj_json" | jq -e . > /dev/null 2>&1; then
                      echo "::error::Invalid JSON for dep_obj_json: $dep_obj_json"
                      # Decide how to handle: skip this dep or fail the step
                      continue # Skip this problematic dependency object
                  fi
                  NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR=$(echo "$NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR" | jq --argjson obj "$dep_obj_json" '. + [$obj]')
                  FOUND_NEW_DEP="true"
                  echo "    AFTER append:  NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR='${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}' (FOUND_NEW_DEP='${FOUND_NEW_DEP}')"
                else # Package IS found
                  echo "    '$packageName' IS ALREADY in package.json (jq exit code: $JQ_EXIT_CODE)."
                fi
              done < <(echo "$IDENTIFIED_DEPS_JSON_STR" | jq -c '.[]')

              echo "Loop finished. Parent shell vars: FOUND_NEW_DEP='${FOUND_NEW_DEP}', NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR='${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}'"
              if [ "$FOUND_NEW_DEP" = "true" ]; then
                echo "Found new dependencies. Preparing artifact file..."
                DEPS_ACTION_REQUIRED="true"
                DEPS_ARTIFACT_UPLOAD_PATH="${{ runner.temp }}/pending_dependencies_payload.json"
                ASSET_INSTRUCTIONS_STR_FOR_DEPS_ARTIFACT=$(jq -r '.assetInstructions // ""' "$TOOL_INFO_FILE_PATH")

                echo "Values for final jq command to create payload file:"
                echo "  TOOL_DIRECTIVE='${TOOL_DIRECTIVE}'"
                echo "  TOOL_DESCRIPTION_FOR_ARTIFACT='${TOOL_DESCRIPTION_FOR_ARTIFACT}'"
                echo "  NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR='${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}' (This must be valid JSON array string)"
                echo "  ASSET_INSTRUCTIONS_STR_FOR_DEPS_ARTIFACT='${ASSET_INSTRUCTIONS_STR_FOR_DEPS_ARTIFACT}'"

                # Validate NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR before using it
                if ! echo "${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}" | jq -e 'type == "array"' > /dev/null 2>&1; then
                    echo "::error::NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR is not a valid JSON array. Value: '${NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR}'"
                    echo "Skipping creation of pending_dependencies_payload.json due to invalid newDeps content."
                    # This will lead to an empty artifact if not handled, or we can prevent upload
                    DEPS_ACTION_REQUIRED="false" # Prevent upload of potentially empty/invalid file
                else
                    jq -n \
                      --arg directive "$TOOL_DIRECTIVE" \
                      --arg description "$TOOL_DESCRIPTION_FOR_ARTIFACT" \
                      --argjson newDeps "$NEW_DEPS_FOR_ARTIFACT_CONTENT_JSON_STR" \
                      --arg assetInst "$ASSET_INSTRUCTIONS_STR_FOR_DEPS_ARTIFACT" \
                      '{toolDirective: $directive, toolDescription: $description, newDependencies: $newDeps, assetInstructions: $assetInst}' > "$DEPS_ARTIFACT_UPLOAD_PATH"

                    echo "Pending NPM dependencies artifact payload file created at: $DEPS_ARTIFACT_UPLOAD_PATH"
                    echo "Contents of $DEPS_ARTIFACT_UPLOAD_PATH:"
                    cat "$DEPS_ARTIFACT_UPLOAD_PATH"
                    # Verify it's not empty
                    if [ ! -s "$DEPS_ARTIFACT_UPLOAD_PATH" ]; then
                        echo "::error:: $DEPS_ARTIFACT_UPLOAD_PATH is empty after jq command!"
                        DEPS_ACTION_REQUIRED="false" # Prevent upload of empty file
                    fi
                fi
              else
                echo "No new dependencies found that require artifact generation. (FOUND_NEW_DEP is '${FOUND_NEW_DEP}')"
              fi
            else
              echo "No 'identifiedDependencies' array or it's empty in '$TOOL_INFO_FILE_PATH'."
            fi

            # ... (Asset processing remains the same) ...
            ASSET_INSTRUCTIONS_STR=$(jq -r '.assetInstructions // ""' "$TOOL_INFO_FILE_PATH")
            if [ -n "$ASSET_INSTRUCTIONS_STR" ] && [ "$ASSET_INSTRUCTIONS_STR" != "null" ]; then
              echo "Asset instructions found. Preparing artifact."
              ASSET_ACTION_REQUIRED="true"
              ASSET_ARTIFACT_UPLOAD_PATH="${{ runner.temp }}/asset_instructions_payload.json"
              jq -n \
                --arg directive "$TOOL_DIRECTIVE" --arg instructions "$ASSET_INSTRUCTIONS_STR" \
                '{toolDirective: $directive, assetInstructions: $instructions}' > "$ASSET_ARTIFACT_UPLOAD_PATH"
              echo "Asset instructions artifact payload:"
              cat "$ASSET_ARTIFACT_UPLOAD_PATH"
            else
              echo "No 'assetInstructions' in '$TOOL_INFO_FILE_PATH'."
            fi
          fi
          echo "Final decision: DEPS_ACTION_REQUIRED=${DEPS_ACTION_REQUIRED}, ASSET_ACTION_REQUIRED=${ASSET_ACTION_REQUIRED}"
          echo "action_required_for_npm_deps=${DEPS_ACTION_REQUIRED}" >> $GITHUB_OUTPUT
          echo "action_required_for_assets=${ASSET_ACTION_REQUIRED}" >> $GITHUB_OUTPUT
          echo "deps_artifact_upload_path=$DEPS_ARTIFACT_UPLOAD_PATH" >> $GITHUB_OUTPUT
          echo "asset_artifact_upload_path=$ASSET_ARTIFACT_UPLOAD_PATH" >> $GITHUB_OUTPUT
          echo "--- End: check_tool_info (Focus on Payload Creation) ---"

      - name: Upload Pending Dependencies Artifact
        if: steps.check_tool_info.outputs.action_required_for_npm_deps == 'true' && steps.check_tool_info.outputs.deps_artifact_upload_path != ''
        uses: actions/upload-artifact@v4
        with:
          name: pending-dependencies-${{ needs.initial_checks.outputs.pr_sha }}
          path: ${{ steps.check_tool_info.outputs.deps_artifact_upload_path }}
          if-no-files-found: error 

      - name: Upload Asset Instructions Artifact
        if: steps.check_tool_info.outputs.action_required_for_assets == 'true' && steps.check_tool_info.outputs.asset_artifact_upload_path != ''
        uses: actions/upload-artifact@v4
        with:
          name: asset-instructions-${{ needs.initial_checks.outputs.pr_sha }}
          path: ${{ steps.check_tool_info.outputs.asset_artifact_upload_path }}
          if-no-files-found: error

  build_and_run_douglas_checker:
    name: 3. Build & Lint Tool
    needs: [initial_checks, analyze_state_and_dependencies]
    if: >
      success() &&
      needs.initial_checks.outputs.critical_initial_checks_passed == 'true' &&
      needs.analyze_state_and_dependencies.outputs.dependency_action_required == 'false' &&
      needs.analyze_state_and_dependencies.outputs.asset_action_required == 'false' && 
      github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions:
      contents: read
    outputs:
      build_command_failed_output: ${{ steps.build_oet.outputs.build_command_failed }}
      lint_errors_captured_for_ai_output: ${{ steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai }}
      douglas_check_step_outcome_output: ${{ steps.douglas_checker_run.outcome }} 
      imgur_screenshot_url_output: ${{ steps.upload_to_imgur.outputs.image_url }} 

    steps:
      - name: Checkout OET Code (PR branch)
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.initial_checks.outputs.pr_sha }}
          fetch-depth: 0 

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22.x'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install OET Dependencies
        run: npm ci

      - name: Prepare for Static Build (Isolate New Tool)
        env:
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "Isolating tool: $TOOL_DIRECTIVE for static check"
          if [ -z "$TOOL_DIRECTIVE" ]; then echo "::error::Tool directive not received."; exit 1; fi
          echo "Removing app/api to prevent 'output: export' issues during this validation build..."
          rm -rf app/api || echo "No app/api to remove."
          if [ -d "app/tool" ]; then
            echo "Pruning other tool directories from app/tool/ ..."
            cd app/tool; ls -d */ 2>/dev/null | grep -v -E "^(${TOOL_DIRECTIVE}/|_components/|_hooks/)$" | xargs -r rm -rf; cd ../.. 
          fi
          echo "Project structure pruned for static check."

      - name: Build OET for Static Export (and check for lint issues)
        id: build_oet
        env: 
          NEXT_OUTPUT_MODE: export 
        run: |
          echo "Attempting static build with NEXT_OUTPUT_MODE=${NEXT_OUTPUT_MODE}..."
          BUILD_LOG_FILE_PATH="${{ runner.temp }}/build_output.log"
          set +e 
          npm run build > "$BUILD_LOG_FILE_PATH" 2>&1
          BUILD_EXIT_CODE=$? 
          set -e 
          echo "npm run build exited with code: $BUILD_EXIT_CODE" 
          echo "--- Start of Build Output (from $BUILD_LOG_FILE_PATH) ---"
          if [ -f "$BUILD_LOG_FILE_PATH" ]; then cat "$BUILD_LOG_FILE_PATH"; else echo "ERROR: Build log file $BUILD_LOG_FILE_PATH not found!"; fi
          echo "--- End of Build Output ---"

          if [ "$BUILD_EXIT_CODE" -ne 0 ]; then
            echo "build_command_failed=true" >> $GITHUB_OUTPUT
            echo "::warning::'npm run build' command failed with exit code $BUILD_EXIT_CODE."
          else
            echo "build_command_failed=false" >> $GITHUB_OUTPUT
            echo "'npm run build' command succeeded."
          fi
          if [ -d "out" ]; then
            echo "build_succeeded_structurally=true" >> $GITHUB_OUTPUT
            echo "Build output directory 'out' found."
          else
            echo "::error::Build output directory 'out' not found."
            echo "build_succeeded_structurally=false" >> $GITHUB_OUTPUT
            if [ "$BUILD_EXIT_CODE" -eq 0 ]; then 
                echo "build_command_failed=true" >> $GITHUB_OUTPUT 
                echo "::error::'out' dir missing despite npm build exit code 0. Marking as command failed."
            fi
          fi
          echo "build_log_path=$BUILD_LOG_FILE_PATH" >> $GITHUB_OUTPUT

      - name: Capture Lint Output and Changed Files for AI Fixer
        id: capture_for_ai_fix
        if: steps.build_oet.outputs.build_command_failed == 'true'
        env:
          TOOL_DIRECTIVE_PATH: app/tool/${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "--- Start of capture_for_ai_fix step ---"
          BUILD_LOG_FILE="${{ steps.build_oet.outputs.build_log_path }}"
          LINT_DATA_DIR="${{ runner.temp }}/lint-data-artifact" # Changed dir name slightly for uniqueness
          mkdir -p "$LINT_DATA_DIR"
          LINT_ERRORS_FILE="$LINT_DATA_DIR/lint_errors.txt"
          FILES_TO_CHECK_FILE="$LINT_DATA_DIR/files_to_check.txt"
          LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG="false" 

          if [ -f "$BUILD_LOG_FILE" ]; then
            if grep -q -E "Failed to compile.|Linting and checking validity of types failed|TypeScript error" "$BUILD_LOG_FILE"; then
              echo "MATCHED: Lint/compile failure found in build log."
              cp "$BUILD_LOG_FILE" "$LINT_ERRORS_FILE"
              find "$TOOL_DIRECTIVE_PATH" \( -name "*.ts" -o -name "*.tsx" \) -type f > "$FILES_TO_CHECK_FILE"
              if [ -s "$FILES_TO_CHECK_FILE" ]; then
                LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG="true"
                echo "Files to check based on TOOL_DIRECTIVE_PATH:"
                cat "$FILES_TO_CHECK_FILE"
              else
                echo "::warning::Build failed with lint-like errors, but no source files found in tool dir '$TOOL_DIRECTIVE_PATH'."
              fi
            else
              echo "Build failed for non-lint reasons based on log indicators (e.g. 'Failed to compile.' not found)."
            fi
          else
            echo "::warning::Build output log ($BUILD_LOG_FILE) not found."
          fi
          echo "lint_errors_captured_for_ai=$LINT_ERRORS_IDENTIFIED_FOR_AI_FLAG" >> $GITHUB_OUTPUT
          echo "--- End of capture_for_ai_fix step ---"

      - name: Upload Lint Failure Artifact for AI Fixer
        if: steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: lint-failure-data-${{ needs.initial_checks.outputs.pr_sha }}
          path: ${{ runner.temp }}/lint-data-artifact/ 
          if-no-files-found: error 

      - name: Serve Static Output Locally
        id: serve_static
        if: steps.build_oet.outputs.build_succeeded_structurally == 'true' && steps.capture_for_ai_fix.outputs.lint_errors_captured_for_ai != 'true'
        run: |
          echo "Starting static server for 'out' directory on port 3001..."
          if sudo fuser 3001/tcp > /dev/null 2>&1; then
            echo "Port 3001 is in use. Attempting to kill process..."
            sudo fuser -k 3001/tcp || echo "Failed to kill process on port 3001, or it was already free."
            sleep 2 
          fi
          npx serve out -l 3001 & 
          SERVER_PID=$!
          echo "server_pid=$SERVER_PID" >> $GITHUB_OUTPUT
          echo "Local server URL: http://localhost:3001"
          echo "Waiting for server on port 3001..."
          timeout 30s bash -c 'until curl -sSf http://localhost:3001 > /dev/null; do echo -n "."; sleep 1; done' \
          || (echo "::error::Local server (npx serve) did not start on port 3001 in time." && (sudo kill -9 $SERVER_PID || true) && exit 1)
          echo "Server is up!"
        continue-on-error: true

      - name: Clone Douglas Checker
        if: steps.serve_static.outcome == 'success'
        run: |
          echo "Cloning Douglas checker..."
          git clone https://github.com/Online-Everything-Tool/douglas.git ./douglas-checker
          if [ ! -d "./douglas-checker" ]; then
            echo "::error::Failed to clone Douglas checker repository."
            exit 1
          fi

      - name: Install Douglas Checker Dependencies
        if: steps.serve_static.outcome == 'success'
        working-directory: ./douglas-checker
        run: |
          echo "Installing Douglas dependencies..."
          if [ -f "package-lock.json" ]; then npm ci; else npm install; fi

      - name: Run Douglas Ethos Check
        id: douglas_checker_run
        if: steps.serve_static.outcome == 'success'
        working-directory: ./douglas-checker
        env:
          TOOL_DIRECTIVE: ${{ needs.initial_checks.outputs.tool_directive }}
        run: |
          echo "Running Douglas check for tool: $TOOL_DIRECTIVE"
          TARGET_URL="http://localhost:3001/tool/$TOOL_DIRECTIVE/"
          SUMMARY_FILE_PATH="$RUNNER_TEMP/douglas_summary.md"
          SCREENSHOT_FILE_PATH="$RUNNER_TEMP/douglas_screenshot.png"
          if [ ! -f "./dist/check-tool.js" ]; then # Adjust if entry point or compile step is different
            echo "Douglas checker not compiled. Attempting to compile..."
            npx tsc || (echo "::error::Failed to compile Douglas checker." && exit 1)
            if [ ! -f "./dist/check-tool.js" ]; then echo "::error::Douglas checker still not found after compile." && exit 1; fi
          fi
          node ./dist/check-tool.js "$TARGET_URL" --outputSummaryFile "$SUMMARY_FILE_PATH" --screenshotPath "$SCREENSHOT_FILE_PATH"
        continue-on-error: true

      - name: Upload Screenshot to Imgur
        id: upload_to_imgur
        if: always() && steps.douglas_checker_run.outcome == 'success' 
        env:
          IMGUR_CLIENT_ID: ${{ secrets.IMGUR_CLIENT_ID }}
        run: |
          SCREENSHOT_FILE="$RUNNER_TEMP/douglas_screenshot.png"
          IMAGE_URL=""
          if [ -f "$SCREENSHOT_FILE" ] && [ -n "$IMGUR_CLIENT_ID" ]; then
            echo "Uploading $SCREENSHOT_FILE to Imgur..."
            RESPONSE=$(curl -s -X POST \
              -H "Authorization: Client-ID $IMGUR_CLIENT_ID" \
              -F "image=@$SCREENSHOT_FILE" \
              -F "type=file" \
              -F "title=Douglas Check for PR ${{ needs.initial_checks.outputs.pr_number }} - ${{ needs.initial_checks.outputs.tool_directive }}" \
              -F "description=Automated ethos check for OET PR. Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
              https://api.imgur.com/3/image)
            UPLOAD_SUCCESS=$(echo "$RESPONSE" | jq -r .success)
            if [ "$UPLOAD_SUCCESS" = "true" ]; then
              IMAGE_URL=$(echo "$RESPONSE" | jq -r .data.link); echo "Screenshot uploaded: $IMAGE_URL"
            else ERROR_MSG=$(echo "$RESPONSE" | jq -r .data.error); echo "::warning::Imgur upload failed: $ERROR_MSG"; fi
          elif [ ! -f "$SCREENSHOT_FILE" ]; then echo "::warning::Screenshot file $SCREENSHOT_FILE not found.";
          elif [ -z "$IMGUR_CLIENT_ID" ]; then echo "::warning::IMGUR_CLIENT_ID secret not set."; fi
          echo "image_url=$IMAGE_URL" >> $GITHUB_OUTPUT
        continue-on-error: true
      
      - name: Upload Douglas Artifacts
        if: always() && steps.serve_static.outcome == 'success' 
        uses: actions/upload-artifact@v4
        with:
          name: douglas-artifacts-${{ github.run_id }} # One artifact for both
          path: |
            ${{ runner.temp }}/douglas_summary.md
            ${{ runner.temp }}/douglas_screenshot.png
          if-no-files-found: warn

      - name: Kill Static Server
        if: always() && steps.serve_static.outputs.server_pid # Only if server_pid was set
        run: |
          echo "Attempting to kill static server PID: ${{ steps.serve_static.outputs.server_pid }}..."
          (sudo kill -9 ${{ steps.serve_static.outputs.server_pid }} || echo "Kill failed or server already stopped.")
          if sudo fuser 3001/tcp > /dev/null 2>&1; then
             echo "Port 3001 still in use after PID kill, attempting fuser kill..."
             sudo fuser -k 3001/tcp || echo "fuser kill also failed or port now free."
          else
             echo "Port 3001 is free."
          fi

  report_pr_status:
    name: 4. Report PR Validation Status & Outcome
    needs: [initial_checks, analyze_state_and_dependencies, build_and_run_douglas_checker]
    if: always() && needs.initial_checks.outputs.critical_initial_checks_passed == 'true' && github.actor != 'dependabot[bot]'
    runs-on: ubuntu-latest
    permissions: { pull-requests: write, actions: read }
    steps:
      - name: Prepare Data for Comment Script
        id: prepare_comment_env
        run: |
          echo "PR_NUMBER_FOR_COMMENT=${{ needs.initial_checks.outputs.pr_number }}" >> $GITHUB_ENV
          echo "TOOL_DIRECTIVE_FOR_COMMENT=${{ needs.initial_checks.outputs.tool_directive }}" >> $GITHUB_ENV
          echo "PR_SHA_FOR_COMMENT=${{ needs.initial_checks.outputs.pr_sha }}" >> $GITHUB_ENV
          echo "INITIAL_CHECKS_RESULT_FOR_COMMENT=${{ needs.initial_checks.result }}" >> $GITHUB_ENV
          echo "CRITICAL_INITIAL_CHECKS_PASSED_FOR_COMMENT=${{ needs.initial_checks.outputs.critical_initial_checks_passed }}" >> $GITHUB_ENV
          echo "PATH_VALIDATION_PASSED_FOR_COMMENT=${{ needs.initial_checks.outputs.path_validation_passed_output }}" >> $GITHUB_ENV
          echo "INVALID_FILES_LIST_FOR_COMMENT=${{ needs.initial_checks.outputs.invalid_files_list_output }}" >> $GITHUB_ENV
          echo "AI_ANALYSIS_SUCCEEDED_FOR_COMMENT=${{ needs.initial_checks.outputs.analysis_succeeded_output }}" >> $GITHUB_ENV
          echo "AI_SCORE_FOR_COMMENT=${{ needs.initial_checks.outputs.ai_analysis_score_output }}" >> $GITHUB_ENV
          echo "AI_IS_TYPO_FOR_COMMENT=${{ needs.initial_checks.outputs.ai_analysis_is_typo_output }}" >> $GITHUB_ENV
          echo "AI_SUGGESTIONS_JSON_FOR_COMMENT=${{ needs.initial_checks.outputs.ai_analysis_suggestions_json_output }}" >> $GITHUB_ENV
          
          echo "ANALYZE_DEPS_RESULT_FOR_COMMENT=${{ needs.analyze_state_and_dependencies.result }}" >> $GITHUB_ENV
          echo "DEP_ACTION_REQUIRED_FOR_COMMENT=${{ needs.analyze_state_and_dependencies.outputs.dependency_action_required }}" >> $GITHUB_ENV
          echo "ASSET_ACTION_REQUIRED_FOR_COMMENT=${{ needs.analyze_state_and_dependencies.outputs.asset_action_required }}" >> $GITHUB_ENV
          
          echo "BUILD_JOB_RESULT_FOR_COMMENT=${{ needs.build_and_run_douglas_checker.result }}" >> $GITHUB_ENV
          echo "BUILD_FAILED_FOR_COMMENT=${{ needs.build_and_run_douglas_checker.outputs.build_command_failed_output }}" >> $GITHUB_ENV
          echo "LINT_ERRORS_CAPTURED_FOR_COMMENT=${{ needs.build_and_run_douglas_checker.outputs.lint_errors_captured_for_ai_output }}" >> $GITHUB_ENV
          echo "DOUGLAS_OUTCOME_FOR_COMMENT=${{ needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome_output }}" >> $GITHUB_ENV
          echo "IMGUR_URL_FOR_COMMENT=${{ needs.build_and_run_douglas_checker.outputs.imgur_screenshot_url_output }}" >> $GITHUB_ENV

      - name: Download Douglas Artifacts (for comment)
        id: download_douglas_artifacts_for_comment
        if: needs.build_and_run_douglas_checker.result != 'skipped' && needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome_output != '' && needs.build_and_run_douglas_checker.outputs.douglas_check_step_outcome_output != 'skipped'
        uses: actions/download-artifact@v4
        with:
          name: douglas-artifacts-${{ github.run_id }}
          path: ${{ runner.temp }}/douglas-artifacts-for-comment
        continue-on-error: true

      - name: Construct and Post PR Comment
        uses: actions/github-script@v7
        env:
          AI_REASONING_TEXT_FROM_NEEDS: ${{ needs.initial_checks.outputs.ai_analysis_reasoning_output }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs').promises;
            const path = require('path'); // Required for path.join
            const { repo, owner } = context.repo; 
            const issue_number = parseInt(process.env.PR_NUMBER_FOR_COMMENT, 10);

            if (isNaN(issue_number)) {
              core.setFailed("VPR Report: PR Number not found for commenting."); return;
            }

            const toolDirective = process.env.TOOL_DIRECTIVE_FOR_COMMENT || "UnknownTool";
            const prHeadShaShort = (process.env.PR_SHA_FOR_COMMENT || 'N/A').substring(0,7);
            const actionRunUrl = `https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}?pr=${issue_number}`;
            let commentBody = `## 🤖 OET Tool PR Validation Status for \`${toolDirective}\`\n\nCommit: \`${prHeadShaShort}\` · [View Action Run](${actionRunUrl})\n\n`;

            const initialChecksOk = process.env.CRITICAL_INITIAL_CHECKS_PASSED_FOR_COMMENT === 'true';
            const depActionRequired = process.env.DEP_ACTION_REQUIRED_FOR_COMMENT === 'true';
            const assetActionRequired = process.env.ASSET_ACTION_REQUIRED_FOR_COMMENT === 'true';
            const buildFailed = process.env.BUILD_FAILED_FOR_COMMENT === 'true';
            const lintErrorsCaptured = process.env.LINT_ERRORS_CAPTURED_FOR_COMMENT === 'true';
            
            const initialChecksJobResult = process.env.INITIAL_CHECKS_RESULT_FOR_COMMENT;
            const analyzeDepsJobResult = process.env.ANALYZE_DEPS_RESULT_FOR_COMMENT;
            const buildJobResult = process.env.BUILD_JOB_RESULT_FOR_COMMENT;
            const douglasOutcome = process.env.DOUGLAS_OUTCOME_FOR_COMMENT;

            // Section 1: Initial Validations
            commentBody += `### 1. Initial PR Validations (Job: ${initialChecksJobResult || 'N/A'})\n`;
            if (initialChecksJobResult === 'success' && initialChecksOk) {
              commentBody += `✅ Passed.\n`;
              commentBody += `\n  **🤖 AI Directive Name Analysis:**\n`;
              if (process.env.AI_ANALYSIS_SUCCEEDED_FOR_COMMENT === 'true') {
                commentBody += `    - Score: **${process.env.AI_SCORE_FOR_COMMENT}** / Typo: ${process.env.AI_IS_TYPO_FOR_COMMENT === 'true' ? '**Yes**' : 'No'}\n`;
                let reasoning = process.env.AI_REASONING_TEXT_FROM_NEEDS || "No reasoning.";
                commentBody += `    - Reasoning:\n        ${reasoning.replace(/\n/g, '\n        ')}\n`;
                try {
                  const suggestions = JSON.parse(process.env.AI_SUGGESTIONS_JSON_FOR_COMMENT || '[]');
                  if (suggestions.length > 0) commentBody += `    - Suggestions: ${suggestions.map(s => `\`${s}\``).join(', ')}\n`;
                } catch (e) { console.warn("Error parsing AI suggestions: " + e.message); }
              } else if (process.env.AI_ANALYSIS_SUCCEEDED_FOR_COMMENT === 'skipped' || !process.env.AI_ANALYSIS_SUCCEEDED_FOR_COMMENT) {
                commentBody += `    - ℹ️ Skipped (e.g., not initial PR open).\n`;
              } else { commentBody += `    - ⚠️ Failed or API error.\n`;}
            } else {
              const invalidFilesMsg = process.env.INVALID_FILES_LIST_FOR_COMMENT ? `Invalid files: ${process.env.INVALID_FILES_LIST_FOR_COMMENT.replace(/%0A/g, ', ')}` : "Check logs.";
              commentBody += `🚨 Failed. Path validation: ${process.env.PATH_VALIDATION_PASSED_FOR_COMMENT === 'false' ? `Failed (${invalidFilesMsg})` : 'Passed (or skipped)'}.\n`;
            }
            commentBody += "\n---\n";

            // Section 2: Dependency & Asset Analysis
            commentBody += `### 2. Dependency & Asset Analysis (Job: ${analyzeDepsJobResult || 'N/A'})\n`;
            if (analyzeDepsJobResult === 'skipped') commentBody += `🟡 Skipped.\n`;
            else if (depActionRequired) commentBody += `⏳ **NPM Dependencies Pending:** ADM will run.\n`;
            else commentBody += `✅ No new NPM dependencies require ADM action.\n`;
            if (assetActionRequired) commentBody += `⏳ **Asset Instructions Present:** AAP will run (future).\n`;
            else commentBody += `✅ No pending asset instructions.\n`;
            commentBody += "\n---\n";

            // Section 3: Build, Lint & Douglas Check
            commentBody += `### 3. Build, Lint & Douglas Check (Job: ${buildJobResult || 'N/A'})\n`;
            if (buildJobResult === 'skipped') commentBody += `🟡 Skipped (due to pending dependencies/assets).\n`;
            else if (buildFailed && lintErrorsCaptured) commentBody += `🟡 **Build Failed (Lint/Build Issues):** ALF will run.\n`;
            else if (buildFailed) commentBody += `🚨 **Build Failed (Non-Lint Issue):** Manual review needed.\n`;
            else { 
              commentBody += `✅ **Local Static Build Successful.**\n`;
              if (douglasOutcome === 'success') commentBody += `✅ **Douglas Ethos Check Passed!**\n`;
              else if (douglasOutcome === 'skipped' || !douglasOutcome) commentBody += `🟡 Douglas Check Skipped / Not Run.\n`;
              else commentBody += `🚨 **Douglas Ethos Check FAILED/Issues!** (Outcome: ${douglasOutcome})\n`;
              
              const summaryFilePath = path.join(process.env.RUNNER_TEMP, "douglas-artifacts-for-comment", "douglas_summary.md");
              try {
                await fs.access(summaryFilePath); 
                const summaryContent = await fs.readFile(summaryFilePath, 'utf8');
                if (summaryContent && summaryContent.trim() && summaryContent.trim() !== 'Douglas summary not available or check skipped.') {
                   commentBody += `\n${summaryContent.trim()}\n`;
                }
              } catch (e) { console.warn(`Douglas summary file '${summaryFilePath}' not found or unreadable in comment script: ${e.message}`); }

              if (process.env.IMGUR_URL_FOR_COMMENT) {
                commentBody += `\n   **Douglas's View (Screenshot):**\n   ![Douglas Screenshot](${process.env.IMGUR_URL_FOR_COMMENT})\n`;
              }
            }
            commentBody += "\n---\n";
            
            // Section 4: Overall Workflow Conclusion
            commentBody += `### 4. VPR Workflow Outcome & Next Steps\n`;
            let vprFailedOverall = false; // Assume success unless a fail condition is met
            if (!initialChecksOk) {
              commentBody += `‼️ **VPR Failed:** Critical initial checks did not pass. Manual review required.`;
              vprFailedOverall = true;
            } else if (depActionRequired) {
              commentBody += `⏳ **VPR Handoff:** NPM dependencies pending. **AI Dependency Manager (ADM)** will be triggered.`;
              vprFailedOverall = true; 
            } else if (assetActionRequired) { 
              commentBody += `⏳ **VPR Handoff:** Asset instructions found. **AI Asset Provisioner (AAP)** will be triggered (future).`;
              vprFailedOverall = true; 
            } else if (buildFailed && lintErrorsCaptured) { 
              commentBody += `⏳ **VPR Handoff:** Build/Lint errors detected. **AI Lint Fixer (ALF)** will be triggered.`;
              vprFailedOverall = true; 
            } else if (buildFailed) { 
              commentBody += `‼️ **VPR Failed:** Build failed for reasons other than lint that ALF can address. Manual review required.`;
              vprFailedOverall = true;
            } else { 
              commentBody += `✅ **VPR Succeeded:** All checks passed! Tool is ready for Netlify deployment and further review.`;
            }
            
            commentBody += `\n\n---\n*OET CI Bot Report for commit \`${prHeadShaShort}\`*`;
            await github.rest.issues.createComment({ owner, repo, issue_number, body: commentBody });

            if (vprFailedOverall) {
              core.setFailed("VPR determined corrective actions are needed or a critical error occurred.");
            } else {
              core.info("VPR completed successfully, no further automated bot actions from this run expected.");
            }